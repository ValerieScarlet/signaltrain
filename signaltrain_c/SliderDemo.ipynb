{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from helpers import audio\n",
    "#%matplotlib inline  # not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "randfunc=np.random.rand\n",
    "\n",
    "def synth_input_sample(t, chooser):\n",
    "    if 'sine' == chooser:\n",
    "        return audio.randsine(t)\n",
    "    elif 'box' == chooser:\n",
    "        return audio.box(t)\n",
    "    elif 'noisysine' == chooser:\n",
    "        return audio.randsine(t) + 0.1*(2*np.random.rand(t.shape[0])-1)\n",
    "    elif 'noisybox' == chooser:\n",
    "        return audio.box(t) * (2*np.random.rand(t.shape[0])-1)\n",
    "    elif 'pluck' == chooser:\n",
    "        return audio.pluck(t)\n",
    "   \n",
    "N_samples = 4096\n",
    "t = np.linspace(0,1,N_samples)\n",
    "old_sig_type = 'box'\n",
    "x = synth_input_sample(t,old_sig_type)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "x_torch = torch.autograd.Variable(torch.from_numpy(x).to(device), requires_grad=False).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knobranges = {'thresh':[-30,0], 'ratio':[1,5], 'attack':[10,800]}\n",
    "knobranges = np.array([[-30,0], [1,5], [10,800]])\n",
    "\n",
    "def compressor(x, thresh=-24, ratio=2, attack=2048, dtype=np.float32):\n",
    "    \"\"\"\n",
    "    simple compressor effect, code thanks to Eric Tarr @hackaudio\n",
    "    Inputs:\n",
    "       x:        the input waveform\n",
    "       thresh:   threshold in dB\n",
    "       ratio:    compression ratio\n",
    "       attack:   attack & release time (it's a simple compressor!) in samples\n",
    "    \"\"\"\n",
    "    fc = 1.0/float(attack)               # this is like 1/attack time\n",
    "    b, a = signal.butter(1, fc, analog=False, output='ba')\n",
    "    zi = signal.lfilter_zi(b, a)\n",
    "    dB = 20. * np.log10(np.abs(x) + 1e-6).astype(dtype)\n",
    "    in_env, _ = signal.lfilter(b, a, dB, zi=zi*dB[0])  # input envelope calculation\n",
    "    out_env = np.copy(in_env).astype(dtype)               # output envelope\n",
    "    i = np.where(in_env >  thresh)          # compress where input env exceeds thresh\n",
    "    out_env[i] = thresh + (in_env[i]-thresh)/ratio\n",
    "    gain = np.power(10.0,(out_env-in_env)/10).astype(dtype)\n",
    "    y = (np.copy(x) * gain).astype(dtype)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_modules import cls_fe_dft, nn_proc\n",
    "from helpers import audio\n",
    "from losses import loss_functions\n",
    "import torch.nn as nn\n",
    "\n",
    "class MPAEC(nn.Module):  # mag-phase autoencoder\n",
    "    \"\"\"\n",
    "        Class for building the analysis part\n",
    "        of the Front-End ('Fe').\n",
    "    \"\"\"\n",
    "    def __init__(self, expected_time_frames, ft_size=1024, hop_size=384, decomposition_rank=25):\n",
    "        super(MPAEC, self).__init__()\n",
    "        self.dft_analysis = cls_fe_dft.Analysis(ft_size=ft_size, hop_size=hop_size)\n",
    "        self.dft_synthesis = cls_fe_dft.Synthesis(ft_size=ft_size, hop_size=hop_size)\n",
    "        self.aenc = nn_proc.AutoEncoder(expected_time_frames, decomposition_rank)\n",
    "        self.phs_aenc = nn_proc.AutoEncoder(expected_time_frames, 2)\n",
    "\n",
    "\n",
    "    def clip_grad_norm_(self):\n",
    "        torch.nn.utils.clip_grad_norm_(list(self.dft_analysis.parameters()) +\n",
    "                                      list(self.dft_synthesis.parameters()),\n",
    "                                      max_norm=1., norm_type=1)\n",
    "\n",
    "    def forward(self, x_cuda, knobs_cuda):\n",
    "        # trainable STFT, outputs spectrograms for real & imag parts\n",
    "        x_real, x_imag = self.dft_analysis.forward(x_cuda)\n",
    "        # Magnitude-Phase computation\n",
    "        mag = torch.norm(torch.cat((x_real.unsqueeze(0), x_imag.unsqueeze(0)), 0), 2, dim=0)\n",
    "        phs = torch.atan2(x_imag, x_real+1e-6)\n",
    "\n",
    "        # Processes Magnitude and phase individually\n",
    "        mag_hat = self.aenc.forward(mag, knobs_cuda, skip_connections='sf')\n",
    "        phs_hat = self.phs_aenc.forward(phs, knobs_cuda, skip_connections=False) + phs # <-- Slightly smoother convergence\n",
    "\n",
    "        # Back to Real and Imaginary\n",
    "        an_real = mag_hat * torch.cos(phs_hat)\n",
    "        an_imag = mag_hat * torch.sin(phs_hat)\n",
    "\n",
    "        # Forward synthesis pass\n",
    "        x_hat = self.dft_synthesis.forward(an_real, an_imag)\n",
    "\n",
    "        return x_hat, mag, mag_hat\n",
    "\n",
    "    \n",
    "# Data settings\n",
    "shrink_factor = 2  # reduce dimensionality of run by this factor\n",
    "time_series_length = 8192 // shrink_factor\n",
    "sampling_freq = 44100. // shrink_factor\n",
    "\n",
    "# Analysis parameters\n",
    "ft_size = 1024 // shrink_factor\n",
    "hop_size = 384 // shrink_factor\n",
    "expected_time_frames = int(np.ceil(time_series_length/float(hop_size)) + np.ceil(ft_size/float(hop_size)))\n",
    "decomposition_rank = 25\n",
    "\n",
    "\n",
    "model = MPAEC(expected_time_frames, ft_size=ft_size, hop_size=hop_size, decomposition_rank=decomposition_rank)    \n",
    "checkpoint = torch.load('modelcheckpoint.tar', map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfd8fd679f604854a78901af1f2c6a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(sig_type=['box','sine','pluck','noisybox','noisysine'],\\\n",
    "    thresh=(-0.5,0.5,0.1),ratio=(-0.5,0.5,0.1),attackrelease=(-0.5,0.5,0.1))\n",
    "def demowidget(sig_type, thresh, ratio, attackrelease):\n",
    "    global old_sig_type, x, x_torch\n",
    "    \n",
    "    # update the model\n",
    "    checkpoint = torch.load('modelcheckpoint.tar', map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    if (sig_type != old_sig_type): # don't regen x unless input changed\n",
    "        x = synth_input_sample(t, sig_type)\n",
    "        x_torch = torch.autograd.Variable(torch.from_numpy(x).to(device), requires_grad=False).float()\n",
    "    old_sig_type = sig_type\n",
    "    \n",
    "    thresh_w = knobranges[0][0] + (thresh+0.5)*(knobranges[0][1]-knobranges[0][0])\n",
    "    ratio_w  = knobranges[1][0] + (ratio +0.5)*(knobranges[1][1]-knobranges[1][0])\n",
    "    attackrelease_w = knobranges[2][0] + (attackrelease+0.5)*(knobranges[2][1]-knobranges[2][0])\n",
    "\n",
    "    y_true = compressor(x, thresh_w, ratio_w, attackrelease_w)\n",
    "    \n",
    "    knobs = np.array([thresh, ratio, attackrelease])\n",
    "    #knobs = (knobs_w - knobranges[:,0])/(knobranges[:,1]-knobranges[:,0]) - 0.5\n",
    "    #print(\"knobs_w, knobs = \",knobs_w, knobs)\n",
    "    knobs_torch = torch.autograd.Variable(torch.from_numpy(knobs).to(device), requires_grad=False).float()\n",
    "\n",
    "    y_pred, mag, mag_hat = model.forward(x_torch.unsqueeze(0), knobs_torch.unsqueeze(0))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(t,x,c='b',lw=1.5, label='Input')\n",
    "    plt.plot(t,y_true,c='r',lw=1.5, label='Target')\n",
    "    plt.plot(t,y_pred.squeeze(0).data.cpu().numpy(),c=(0,0.5,0,0.75),lw=1.5, label='Predicted')\n",
    "    \n",
    "    thresh_line = 10**(thresh_w/20.0)*np.ones(2) # show threshold line\n",
    "    plt.plot([t[0],t[-1]],thresh_line,c='k',lw=1, linestyle='dashed', label='Threshold') \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim(-1,1)\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
