{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from helpers import audio\n",
    "from nn_modules import nn_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "randfunc=np.random.rand\n",
    "\n",
    "def synth_input_sample(t, chooser):\n",
    "    if 'sine' == chooser:\n",
    "        return audio.randsine(t)\n",
    "    elif 'box' == chooser:\n",
    "        return audio.box(t)\n",
    "    elif 'noisysine' == chooser:\n",
    "        return audio.randsine(t) + 0.1*(2*np.random.rand(t.shape[0])-1)\n",
    "    elif 'noisybox' == chooser:\n",
    "        return audio.box(t) * (2*np.random.rand(t.shape[0])-1)\n",
    "    elif 'pluck' == chooser:\n",
    "        return audio.pluck(t)\n",
    "   \n",
    "N_samples = 4096\n",
    "t = np.linspace(0,1,N_samples)\n",
    "old_signal_type = 'box'\n",
    "x = synth_input_sample(t,old_signal_type)\n",
    "\n",
    "device = torch.device('cpu')\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "x_torch = torch.autograd.Variable(torch.from_numpy(x).to(device), requires_grad=False).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "knobranges = np.array([[-30,0], [1,5], [10,2048]])\n",
    "\n",
    "# Data settings\n",
    "shrink_factor = 2  # reduce dimensionality of run by this factor\n",
    "time_series_length = 8192 // shrink_factor\n",
    "sampling_freq = 44100. // shrink_factor\n",
    "\n",
    "# Analysis parameters\n",
    "ft_size = 1024 // shrink_factor\n",
    "hop_size = 384 // shrink_factor\n",
    "expected_time_frames = int(np.ceil(time_series_length/float(hop_size)) + np.ceil(ft_size/float(hop_size)))\n",
    "\n",
    "# Define model\n",
    "model = nn_proc.MPAEC(expected_time_frames, ft_size=ft_size, hop_size=hop_size)\n",
    "\n",
    "# Load model weights\n",
    "checkpoint_file = 'modelcheckpoint.tar'\n",
    "checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5208f0caad9b490e91fa25fb73105a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define interactive widgets and their handler routine\n",
    "@interact(signal_type=['box','sine','pluck','noisybox','noisysine'],\\\n",
    "    threshold=(knobranges[0][0],knobranges[0][1],1), \\\n",
    "    ratio=(knobranges[1][0],knobranges[1][1],0.1), \\\n",
    "    attackrelease=(knobranges[2][0],knobranges[2][1],50))\n",
    "def demowidget(signal_type, threshold, ratio, attackrelease):\n",
    "    global old_signal_type, x, x_torch\n",
    "    \n",
    "    # update the model\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    if (signal_type != old_signal_type): # don't regen x unless input changed\n",
    "        x = synth_input_sample(t, signal_type)\n",
    "        x_torch = torch.autograd.Variable(torch.from_numpy(x).to(device), requires_grad=False).float()\n",
    "    old_signal_type = signal_type\n",
    " \n",
    "    y_true = audio.compressor(x, threshold, ratio, attackrelease)\n",
    "\n",
    "    thresh_nn = (threshold-knobranges[0][0])/(knobranges[0][1]-knobranges[0][0]) - 0.5\n",
    "    ratio_nn = (ratio-knobranges[1][0])/(knobranges[1][1]-knobranges[1][0]) - 0.5\n",
    "    attack_nn = (attackrelease-knobranges[2][0])/(knobranges[2][1]-knobranges[2][0]) - 0.5 \n",
    "    knobs = np.array([thresh_nn, ratio_nn, attack_nn])\n",
    "    knobs_torch = torch.autograd.Variable(torch.from_numpy(knobs).to(device), requires_grad=False).float()\n",
    "\n",
    "    y_pred, mag, mag_hat = model.forward(x_torch.unsqueeze(0), knobs_torch.unsqueeze(0))\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(t,x,c='b',lw=1.5, label='Input')\n",
    "    plt.plot(t,y_true,c='r',lw=1.5, label='Target')\n",
    "    plt.plot(t,y_pred.squeeze(0).data.cpu().numpy(),c=(0,0.5,0,0.75),lw=1.5, label='Predicted')\n",
    "    \n",
    "    thresh_line = 10**(threshold/20.0)*np.ones(2) # show threshold line\n",
    "    plt.plot([t[0],t[-1]],thresh_line,c='k',lw=1, linestyle='dashed', label='Threshold') \n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylim(-1,1)\n",
    "    plt.show()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
